{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some imports and jupyter setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['lines.linewidth'] = 0.25\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.linewidth'] = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "# device = torch.device('cpu') # uncomment if no GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use a progressive GAN.\n",
    "\n",
    "Let's analyze a pretrained model.  I've chosen an outdoor church model.\n",
    "\n",
    "You can uncomment the model of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.hub\n",
    "from netdissect import nethook, proggan\n",
    "\n",
    "# n = 'proggan_bedroom-d8a89ff1.pth'\n",
    "n = 'proggan_churchoutdoor-7e701dd5.pth'\n",
    "# n = 'proggan_conferenceroom-21e85882.pth'\n",
    "# n = 'proggan_diningroom-3aa0ab80.pth'\n",
    "# n = 'proggan_kitchen-67f1e16c.pth'\n",
    "# n = 'proggan_livingroom-5ef336dd.pth'\n",
    "# n = 'proggan_restaurant-b8578299.pth'\n",
    "\n",
    "url = 'http://gandissect.csail.mit.edu/models/' + n\n",
    "sd = torch.hub.load_state_dict_from_url(url)\n",
    "model = proggan.from_state_dict(sd).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GAN generator is just a function z->x that transforms random z to realistic images x.\n",
    "\n",
    "To generate images, all we need is a source of random z.  Let's make a micro dataset with six random z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netdissect import zdataset\n",
    "zds = zdataset.z_dataset_for_model(model, size=30, seed=5555)\n",
    "len(zds), zds[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can just invoke model(z[None,...]) to generate a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By data\n",
    "model(zds[0][0][None,...].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netdissect import renormalize, show\n",
    "# from IPython.display import display\n",
    "\n",
    "show([\n",
    "    [renormalize.as_image(model(z[None,...].to(device))[0])]\n",
    "    for [z] in zds\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze what a model is doing inside, we can wrap it with an InstrumentedModel, which makes it easy to hook or modify a particular layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add a summary of what InstrumentedModel can do.\n",
    "# retain a layer, get a retined layer, edit a layer\n",
    "\n",
    "from netdissect import nethook\n",
    "if not isinstance(model, nethook.InstrumentedModel):\n",
    "    model = nethook.InstrumentedModel(model)\n",
    "    model.retain_layer('layer4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the model and inspect the internal units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netdissect import imgviz\n",
    "from importlib import reload\n",
    "from netdissect import upsample\n",
    "reload(upsample)\n",
    "reload(imgviz)\n",
    "img = model(zds[0][0][None,...].to(device))\n",
    "acts = model.retained_layer('layer4')\n",
    "\n",
    "# This is the intermediate value inside the network - how much data is it?\n",
    "acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show([[1, 2, 3], [3,4], [5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv = imgviz.ImageVisualizer((100, 100), image_size=(256,256))\n",
    "show(\n",
    "    [['unit %d' % u,\n",
    "      [iv.image(img[0])],\n",
    "      [iv.masked_image(img[0], acts, (0,u))],\n",
    "      [iv.heatmap(acts, (0,u), mode='nearest')],\n",
    "     ] for u in range(400, 424)]  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each unit has a idfferent scale, which makes the heatmaps harder to interpret.\n",
    "\n",
    "We can normalize the scales by collecting stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acts.shape)\n",
    "print(acts.permute(0, 2, 3, 1).contiguous().view(-1, acts.shape[1]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netdissect import tally\n",
    "reload(tally)\n",
    "upfn = upsample.upsampler(\n",
    "    (64, 64),                     # The target output shape\n",
    "    (8, 8),                       # The source data shape\n",
    "    image_size=(256, 256)         # The actual image shape\n",
    ")\n",
    "\n",
    "# To collect stats, define a function that returns 2d [samples, units]\n",
    "def compute_samples(batch):\n",
    "    image_batch = batch[0].cuda()\n",
    "    _ = model(image_batch)\n",
    "    acts = model.retained_layer('layer4')\n",
    "    # hacts = upfn(acts)\n",
    "    return acts.permute(0, 2, 3, 1).contiguous().view(-1, acts.shape[1])\n",
    "\n",
    "rq = tally.tally_quantile(compute_samples, zds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells me now, for example, what the means are for channel,\n",
    "# rq.mean()\n",
    "# what median is,\n",
    "# rq.quantiles([0.5])\n",
    "# Or what the 99th percentile quantile is.\n",
    "# rq.quantiles([0.99])\n",
    "\n",
    "rq.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see all the activations on a reasonable scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iv = imgviz.ImageVisualizer((100, 100), image_size=(256,256), quantiles=rq)\n",
    "show(\n",
    "    [[\n",
    "       'unit %d' % u,\n",
    "       [iv.image(img[0])],\n",
    "       [iv.masked_image(img[0], acts, (0,u))],\n",
    "       [iv.heatmap(acts, (0,u), mode='nearest')],\n",
    "    ]\n",
    "      for u in range(400, 424)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quantify what's inside these images by segmenting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO, I need to make this make this downloadable\n",
    "\n",
    "from netdissect import segmenter\n",
    "segmodel = segmenter.UnifiedParsingSegmenter(segsizes=[256])\n",
    "seglabels = [l for l, c in segmodel.get_label_and_category_names()[0]]\n",
    "\n",
    "indices = range(200,204)\n",
    "batch = torch.cat([dataset[i][0][None,...] for i in indices])\n",
    "preds = model(batch.cuda()).max(1)[1]\n",
    "imgs = [renormalize.as_image(t, source=dataset) for t in batch]\n",
    "prednames = [classlabels[p.item()] for p in preds]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}